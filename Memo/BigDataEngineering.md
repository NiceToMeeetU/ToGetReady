# BigDataEngineering

### Spark引擎中，一个任务从提交到执行的具体过程是怎样的？

- 构建DAG；
- DAGScheduler以是否Shuffle为依据将DAG切分成Stage，将Stage中生成的Task以TaskSet的形式给TaskScheduler；
- TaskScheduler调度Task，根据资源情况分配到相应的Executor中；
- 各个Executor接收Task，放入线程池里进行。

### 简要介绍一下你所构建过的数据仓库？

Lambda架构，批处理流处理两套类似的逻辑。

### ETL中为什么要使用Kafka组件，起到了哪些作用？

为什么要在我们的数据处理平台中使用这样的一个消息系统呢？消息系统能给我们带来什么样的好处呢？

- 解耦

  在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。

- 冗余

  有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。[消息队列](https://cloud.tencent.com/product/cmq?from=10680)把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的"插入-获取-删除"范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。

- 扩展性

  因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。

- 灵活性 & 峰值处理能力

  在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。

- 顺序保证

  在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。Kafka保证一个Partition内的消息的有序性。

- 缓冲

  在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。该缓冲有助于控制和优化数据流经过系统的速度。

### 谈一谈对实时数仓的认识？

那我就从实施数仓发展历史、挑战、建模思路三方面展开

- 发展历史

  最开始从无到有，以Storm为代表的实时计算框架出现，大数据摆脱了Map Reduce的单一计算方式，有了当天算当天数据的能力；接着从有到全，Lambda、Kappa等架构初步出现，将实时计算与离线计算集合到一起；第三阶段是从全到简，以Flink为代表的支持窗口计算的六十框架出现，使得离线实时的处理逻辑能够真正统一起来；未来的发展应该是从架构走向工具，基于服务分析一体化的设计理念，同意分析型数据库和业务型数据库，实现数仓彻底实时化，不再存在离线与实时的区分。

- 实时数仓的挑战

  - ==时效性==挑战：尽量降低延迟，快快快！这是最大的挑战；
  - ==准确性==挑战：需要与离线数据处理一致的完整的质量保证体系；
  - ==稳定性==挑战：实时计算过程中的错误成本极高；
  - 灵活性挑战：海量高并发，需求频繁变更。

- 实时数仓维度建模思路区别：

  - `ODS`：批流一体统一了数据源，无需考虑再建ODS层，直接利用数据源即可；
  - `DWD`：离线方案中为了提高明细表的使用便捷程度，往往会把一些常用的维度退化到事实表；但实时方案出于时效性的考虑，清醒与不退化或者只退化不变的维度；
  - `DWS`：需要根据业务情况不同具体确定，差异较大。离线方案中一般针对比较成熟的业务会将维度逐级上卷，这样可以对逻辑收口，提高下游复用率。实时中汇总层目的在于与计算、提升效率和保证指标的一致性，不能让链路太长；
  - `DIM`：维表需要实时更新，非常重要；
  - `ADS`：与离线数仓一致。

- 总结：

  - 实时数仓不能完全替代离线数仓，尤其对准确性要求非常高的场景，离线可以通过数据回滚等对结果进行兜底；
  - 公共层需要做好重点建设，通过公共曾缩减计算数据量以面对实时流量暴涨的问题；
  - 需要做好资源的错峰使用。

- https://mp.weixin.qq.com/s/9Pe4N7Sfbe2-xsomg4b6ww



