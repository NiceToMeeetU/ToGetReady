# 机器学习基础

[TOC]

> https://blog.csdn.net/jiaoyangwm/article/details/79805939?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control
>

## 集成学习

### boosting和bagging有何区别？

- boosting是串行训练基分类器，各分类器之间有依赖，基本思路是将基分类器层层叠加，每次迭代对之前分错的样本给与更高权重，测试时根据各层分类器的加权获得最终结果，迭代式学习；

- bagging并行训练基分类器，各基分类器之间无强依赖，每个单独学习，最后再投票决策，分而治之学习；

- 两者提高基分类器性能的本质（故基分类器最好是本身对样本分布较为敏感的不稳定的）：

  - Boosting——消除偏差。
    通过逐步聚焦于基分类器分错的样本，减小集成分类器的偏差；
    训练过程使得各弱分类器之间强相关、缺乏独立性，故并不会降低方差；
  - Bagging——有效降低方差
    集成投票使得基分类器可能出现的过拟合现象得到了平缓，所以最终模型笔各个独立的模型更平滑
    一直考虑通过各种方法来增加独立性，从而有效降低方差

  > 偏差：由采样的所有训练数据集训练处的所有模型的输出的平均值与真实模型输出之间的偏差；
  >
  > 方差：由采样的所有训练数据集训练出的所有模型的输出的方差。

### 集成学习常用什么基分类器，为什么？

最常使用决策树作为基分类器：

- 决策树可以较方便地将样本的权重整合到训练过程中，而不需要使用过采样的方法；
- 可以通过调节树的层数来折中平衡决策树的表达能力和泛化能力；
- 数据样本的扰动对决策树影响较大，故不同子样本集合生成的决策树基分类器随机性较大。
- 神经网络也可做基分类器，同样不稳定，且方便调节层数、权值等引入随机性。

### 简单说一下AdaBoost？

- 对分类正确的样本降低权重；
- 对分类错误的样本升高或保持权重不变；
- 在模型融合过程中，根据错误率对基分类器进行甲醛融合，错误率低的分类器拥有更大话语权。

## GBDT专题

### 简单介绍一下GBDT？

GBDT是一种基于boosting思想的加法模型，训练时采用前向分布算法进行贪婪的学习，每次基于前 t - 1 棵树的预测结果和训练样本真实值的残差来迭代学习一棵新的CART树。

Gradient Boosting的基本思想就是根据当前模型损失函数的负梯度信息来训练新加入的弱分类器，然后将训练好的弱分类器以累加的形式结合到现有模型中。

### 说一下GBDT的原理？



### 决策树节点分裂是如何选择特征的和剪枝的？

决策树的学习是一个递归地选择最优特征，并根据该最优特征对训练数据进行分割，使得对各个子数据集有一个更好的分类的过程。

决策树的剪枝通过极小化决策树整体的损失函数或代价函数实现

> 损失函数的极小化等价于正则化的极大似然估计



以常见的CART树为例，基于基尼系数或平方误差和最小化的原则进行特征选择，生成二叉树

对所有可能的特征A及其所有可能的分割点a中，选择其基尼系数最小的特征及其分割点作为最优特征和最佳切分点，将训练数据依该特征分配到两个子节点中去。

### 说一下基尼系数和信息增益？

- 基尼系数：

  分类问题中，假设有K个类，样本点属于第k类的概率为pk，则概率分布的基尼系数定义为1减去所有概率的平方和，表征样本集合经过某个特征A分割后的不确定性，基尼系数数值越大，样本集合的不确定性就越大

### 分类树与回归树的区别是什么？



### 对比一下GBDT与Random Forest？

（考虑讲到  **Bias **和 **Variance** ）

### 常用的三大主流GBDT工程实现？

- XGBoost
- LightGBM
- CatBoost，更好地处理类别特征

### GBDT具体使用的是哪种树？分类树和回归树的区别是什么？

GBDT 用 CART树构建 Boosting 模型，不论分类还是回归，都是用的是回归树，因为分类树无法处理连续值，要利用连续的负梯度信息学习。

- CART里分类节点分裂时特征选择用gini, 回归用均方差mse，度量目标是对于划分特征A，对应划分点s两边的数据集D1和D2，求出使D1和D2各自集合的均方差最小，同时D1和D2的均方差之和最小。
- 2.对于决策树建立后做预测的方式，CART分类树采用叶子节点里概率最大的类别作为当前节点的预测类别。回归树输出不是类别，采用叶子节点的均值或者中位数来预测输出结果。

### GBDT与AdaBoost有何区别？

都属于`Boosting` 方法，但损失函数不同，

`AdaBoost` 自适应Boosting算法，通过提升错分数据的权重来定位模型不足，前一个基分类器分错的样本会得到权重加强，加权后的全体样本再被用来训练下一个基分类器；

`GBDT` 通过拟合梯度来定位模型不足。每一次的计算是为了拟合减少上一次的残差，进而再残差减少（负梯度）的方向上建立一个新模型。

### 简单讲一下XGBoost方法？

XGBoost是GBDT算法的一种高效的工程实践，基于Gradient Boosting的集成学习思想即更具当前模型损失函数的负梯度信息来训练新加入的基分类器。一般的GBDT算法基于决策树预测的残差进行迭代式地学习，在决策树构建完成后进行必要的剪枝，基分类器一般是CART树。XGBoost在工程上做了大量的优化，主要有：

- 一是支持更多类型的基分类器；
- 二是显式地加入正则项控制模型复杂度，有利于防止过拟合，从而提高模型的泛化能力；
- 三是训练过程对损失函数进行了二阶泰勒展开，过程更高效；
- 四是对缺失值的有效填充策略。

其他还有缓存感知、核外计算、列抽样行抽样等计算机方面的优化过程等，具有很强工程适用性。

### 为什么选择 XGBoost 模型？

因为该问题时手工提取的显式特征，维度不高，且没有缺失值，所以我们并不需要把太多的精力放到模型的选择和调参上。实际上构建出五层深度的特征数组后，我们直接调用了所有常见分类器进行测试，效果差异不大。选择XGBoost也是因为之前用的多比较熟悉。

在其他场景下，选择XGB模型主要考虑到三点：

- 一是存在严重的数据缺失问题，xgb可以较好地自动处理缺失值；
- 二是大规模数据，xgb有很好的并行特性；
- 三是特征维度过多，需要做特征优化选择。





### 有尝试过XGBoost和GBDT的区别么？在你的项目上是什么导致了这个区别？

[灵魂拷问，你看过Xgboost原文吗？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/86816771)

尝试过。XGBoost的精度要比GBDT的高且效率也更高，我认为精度高的最大原因是大部分的CTR特征中，我们会将一些稀疏的离散特征转化为连续特征，会产生很多含有缺失值的稀疏列，导致原始GBDT算法效果不好，而XGBoost会对缺失值做一个特殊的处理，在非分布式的效率更高是因为建树时采用了基于分位数的分割点估计算法。

XGBoost使GBDT算法的一种很好的工程实现，并且再算法上做了一些优化，主要的优化在以下几点：

- 首先XGBoost采用二姐泰勒展开拟合损失函数，可以加速模型收敛，加了一个衰减因子，作为学习率，可以减少加进来的树对于原模型的影响，让树的数量变得更多；
- 在原GBDT模型的基础上加了个正则项，对于树的叶子节点的权重做了约束；
- 增加了在随机森林上常用的col subsample 策略；
- 不需要遍历所有可能的分裂点，提出了一种估计分裂点的算法，在工程上做了一个算法的并发实现。









### GBDT的基本原理，优缺点

梯度提升决策树(Gradient Boosting Decision Tree)，基于决策树预测的残差进行迭代的学习。

- 基本思想

  根绝当前模型损失函数的负梯度信息来训练新加入的弱分类器，然后将训练好的弱分类器以累加的形式结合到现有模型中。

- 优点

  - 预测阶段计算速度快，树间可并行；
  - 分布稠密的数据集上，泛化性能和表达能力都很好；
  - 采用决策树作为基分类器可具有很好的解释性和鲁棒性，能够自动发现特征间的高阶关系，不需要对数据归一化等；

- 缺点：

  - 训练需要串行，速度慢；
  - 高维稀疏数据集上表现较差；
  - 解决文本分类特征问题上优势不明显；

### XGBoost大魔王

原始的GBDT算法基于经验损失函数的负梯度来构造决策树，只是在决策树构建完成后再进行剪枝。而XGBoost再决策树构建阶段就加入了正则项；

XGBoost本质就是机器学习算法GBDT的高效工程实现：

- 显式地加入了正则项来控制模型复杂度；
- 训练过程对cost函数二阶泰勒展开，同时利用一阶二阶信息；
- 相比于GBDT可以支持除CART之外的多种基分类器；
- 每次迭代可以不用全部数据，而是类似随机森林，支持对数据进行采样；
- 能够自动学习缺失值的处理策略。

### XGBoost对缺失值是如何处理的？

在普通的GBDT策略中，对于缺失值的处理是先手动对缺失值进行填充，然后当做正常值处理，这样的人工填充会影响数据分布，且没有理论支持。而XGBoost采取的策略是先不处理含有缺失值的样本，先一句正常值数据计算特征的分割点，然后再遍历每个分割点的时候，尝试将缺失样本划入左子树和右子树，选择使损失最优的情况。

### XGBoost算法有哪些参数？

- 架构参数：
  - booster：基分类器选择，CART或其他线性模型；
  - n_estimator：迭代次数；
  - objectvie：目标函数，回归MSE，二分类用Logistic， 多分类用softmax
- 弱分类器参数：
  - max_depth
  - min_child_weight：最小子节点权重；
  - gamma：分裂带来的随时最小阈值
  - 特征采样比例
  - 正则化参数等
- 并行计算参数：
  - 并发线程数
  - 正负样例不平衡的比例

### XGBoost相比GBDT的优化有哪些？

三方面：

- 一是算法本身的优化，相比GBDT只支持CART决策树，还引入了其他线性分类器，损失函数加上正则化惩罚防止过拟合，对损失函数做了二阶泰勒展开；
- 二是算法运行效率的优化，对每个基学习器建立的过程做并行选择计算；
- 三是算法鲁棒性的优化，如缺失值的处理方式。

### XGBoost调参有哪些经验？



### XGBoost 的正则化是如何实现的？

- 设置了两个正则项：
  - 树的叶子节点个数T的惩罚；
  - 叶子节点的权重的L2正则。
- 引入收缩率，不断收窄新增加的权重；
- 列采样
- 树最大深度。

### XGboost 的并行化是如何实现的？

XGB的并行在特征的粒度上。决策树学习最耗时的步骤就是选择最佳分割点，xgb在训练之前对数据做了预排序，保存成block结构，在后面的迭代中重复使用这个节点，减少了计算量

### 为什么XGBoost二阶泰勒展开了速度更快？

优化算法中的牛顿法里已经证实，一阶导数指引梯度方向，二阶导数指引梯度方向如何变化，那自然用二阶的信息会让收敛更快。

另外我记得官网里说过，目标函数是MSE时，展开式一阶项（残差） + 二阶项的形式，而做二分类的话用logloss直接展开就没有，为了有一个统一的目标函数形式就用泰勒做二阶展开，求导计算方式一致简单，也便于自定义loss function

### GBDT和XGBoost 的剪枝策略有何不同？

剪枝是我们对优化决策树类模型、减少其过拟合的通俗说法。

- GBDT中使用的CART树，其剪枝策略就是单个CART树的基于代价复杂度的后剪枝策略；
- XGB是在生成树的过程中，按照分裂后的信息增益是否大于一个阈值伽马，确定是否分裂，实现剪枝。

### 简单介绍一下LightGBM？

实际是`GBDT with GOSS and EFB`，

通俗解释：LGB的优化方法是，在保留大梯度样本的同时，随机地保留一些小梯度样本，同时放大了小梯度样本带来的信息增益。

https://blog.csdn.net/GFDGFHSDS/article/details/104779767

### XGBoost和LightGBM有何区别？

- 决策树生长策略：`level-wise` vs `leaf-wise`；

  level-wise: 对每一层所有节点做无差别分裂，实际上可能有些节点的增益非常小，带来了没必要的开销；

  leaf-wise: 在当前叶子节点中选择分裂收益最大的节点进行分裂。

- 类别特征：`不支持，需独热编码` vs `直接支持`；

- 采样过程：`pre-sorted or exact greedy` vs `Histogram`；

- 

### LightGBM的并行化是如何实现的？

- `feature parallel`特征并行处理；
- `'data parallel`数据并行处理。

---

## 模型评估

### 常见的模型评估指标有哪些，分别有何局限性？

- 准确率

  容易受到样本不平衡导致的假高

### 如何绘制ROC曲线？

一般通过设置连续的阈值截断点，以假阳率为横坐标，真阳率为纵坐标绘制一系列点，再按照从左到右，从下到上的顺序依次连接即可。

更直观的说法：对一个二分类任务，假定其样本中有P个正例，N个负例，将所有样本通过模型计算出分类概率，按照概率结果从大到小的顺序排列依次遍历，从坐标轴的（0，0）点开始，每遇到一个正样本，就向Y轴方向移动1/P距离，遇到一个负样本，就向X轴方向移动1/N距离，一直到达（1，1）点，即完成ROC曲线的绘制。

ROC曲线横坐标是==假阳率==，纵坐标是==真阳率==，所以也可以叫做==假阳-真阳曲线==，描述了模型的敏感性与特异性的平衡，曲线越接近 y=1 说明模型效果越好。

- 横坐标-假阳率，`False Positive Rate`

  $FPR = \frac{FP}{N} = \frac{FP}{FP+TN}$

- 纵坐标-真阳率，`True Positive Rate`

  $TPR=\frac{TP}{P} = \frac{TP}{TP+FN}$

### ROC曲线相比PR曲线有何特点？

- 两者都是通过将阈值从高到低依次阶梯状设置后绘制成对的评估指标后依次连接形成的；
- 两者都能反映模型敏感性与特异性的平衡关系；
- 纵坐标-横坐标：==ROC曲线是真阳率-假阳率，PR曲线是精确率-召回率==；
- ROC曲线由西南到东北，PR曲线一般由西至东南；

当正负样本分布发生变化时，ROC曲线的形状能基本保持不变，而P-R曲线一般会发生明显的形态变化，所以ROC曲线能更稳定的反映模型本身的好坏。

### AUC的意义？

> https://tracholar.github.io/machine-learning/2018/01/26/auc.html
>
> https://www.zhihu.com/question/39840928

- 用于衡量算法的排序能力，ROC曲线的积分面积，取值`[0,1]`，越大越好，越大说明越可能将正样本的预测概率值排在负样本前面。
- AUC的评估指标不依赖于判决阈值的设置。
- 数值上可以看错随机从样本中选取一对正负样本，预测其正样本的得分大于负样本的概率。
- 其排序特性决定了如果所有样本的得分都加上一个额外的常数，不会改变该概率，所以在广告等需要绝对点击率计算的场景下，AUC并不适合作为评估指标，而应当选择使用Logloss。
- AUC对正负样本比例不敏感
- AUC的计算可以通过其概率意义按照所有样本的概率排序后一次计算，有显式的数量公式，故可以直接通过SQL求解。
- 不同业务不同模型的AUC指标差异巨大， 要根据实际情况具体对比选择。



### 不平衡数据的分类模型应该用什么指标？

不能单一地使用准确率指标，很容易反映出不真实的指标；

应当使用==精确率==，==召回率==，==F1==，==AUC==等指标判断模型对少数类的性能。

### 如何看待余弦距离和欧氏距离的关系，还用过哪些距离度量？



### 简述F值统计量的含义？

是精确率`Precision` 和 召回率`Recall`的加权调和平均值$$F = \frac{(a^2 + 1)P*R}{a^2 (P+R)} $$，`a=1`时即`F1-Score`。

用于同时综合评估这两者指标。

### 什么是K-fold交叉验证？

K-fold 交叉验证就是把原始数据随机分成 K 个部分，在这 K 个部分中选择一个作为测试数据，剩余的 K-1 个作为训练数据。交叉验证的过程实际上是将实验重复做 K 次，每次实验都从 K 个部分中选择一个不同的部分作为测试数据，剩余的数据作为训练数据进行实验，最后把得到的 K 个实验结果平均，用于评价模型的泛化能力，从而进行模型选择。



### 说说方差与偏差？

监督学习中，模型的泛化误差主要来源于两个方面：偏差与方差。

- 偏差

  偏差指由所有的训练数据训练得到的所有模型的输出的平均值与真实输出之间的偏差

  本质原因是对模型算法的错误假设或者模型训练不到位；

  一般来说偏差直接在训练样本上就能体现出来；

  偏差低说明射箭射的准。

  Boosting集成可以降低偏差

- 方差

  方差指由所有的训练数据训练得到的所有模型的输出的方差

  本质原因是模型复杂度相对于训练样本过高

  一般来说方差带来的误差通常体现在测试误差相对于训练误差的增量上。

  方差低说明射箭射的稳

  Bagging集成可以降低方差

## 数据分布

### 如何解决过拟合问题？

是什么？怎样做？实际经验？

模型太过复杂泛化性能差；增大数据量，降低复杂度，参数加正则，多集成学习；暂无

### 为什么增加正则项、减少复杂度就能避免过拟合？

### 为什么减少模型的复杂度就能解决过拟合问题？



### 如何解决欠拟合问题？

是什么？怎样做？实际经验？

模型不能有效拟合数据；添加新特征，提升复杂度，减小正则化。



### 如何应对不平衡数据集？

两种思路：

- 从数据入手，

### 

### 哪些机器学习算法需要做归一化处理？

- 需要做归一化处理的：
  - 基于距离计算的模型：KNN， k-means；
  - 通过梯度下降法求解的模型：线性回归，逻辑回归，支持向量机，神经网络；
- 不需要归一化的：
  - 树型模型、贝叶斯模型不需要归一化，因为其不关心变量的值，二是关心变量的分布和变量之间的条件概率，如决策树，随机森林等。
  - 数值缩放不影响树的分裂点位置。



### 超参数调优有哪些方法？



---

- 

### SVM支持向量机的支持向量究竟是什么？



### 逻辑回归与线性回归有何区区别？

逻辑回归是分类问题，线性回归是回归问题，本质区别。

都是用了极大似然估计来对训练样本建模



### 逻辑回归如何解决多分类问题？



### 决策树有哪些常用启发函数？不同种类的决策树有何区别？

简单直观记忆：

- ID3——最大信息增益，只能用于分类；

  信息增益即经验熵减去经验条件熵

- C4.5——最大信息增益比，只能用于分类；

  信息增益比即信息增益比上取值熵

- CART——最大基尼系数，用于分类和回归。

  基尼系数描述数据的纯度

### 如何对决策树进行剪枝？

剪枝是为了降低决策树模型的复杂度，提高其泛化性能：

- 预剪枝

  在树生成过程中剪枝，方法有：

  - 设置一定的深度阈值；
  - 设置一定的子节点样本数阈值；
  - 设置准确度提升阈值。

  需要经验确定策略，有一定的欠拟合风险；

- 后剪枝

  在树完全生成后进行剪枝，得到的泛化能力会更高，但更费时间。

  代价复杂度剪枝等

### 说说对聚类的认识，讲一下常用的聚类算法？





### python中a==b和a is b有何区别？

- a == b，判断两只是否相等；
- a is b，判断两值是否相等且地址是否相同；
- 一般来说，is 比 = =大，即 a is b 为真 a==b 一定为真；a = = b 为真 a is b不一定为真；
- 也有例外情况，a = float(nan), b=a后，虽然两个都是nan，且 a is b，但是有规定 nan 与任意对象比较哪怕是自己结果都是False，所以此时 a==b 不成立

### 如果项目业务需要强解释性，模型应该如何选择？

黑箱模型即不可用，需要在这三种中选择：

- tree-based model
- logistic regression
- linear kernel svm



### 熟悉哪些降维方法？

降维是为了剔除高维数据中的冗余和噪声，发掘数据内部的特性，从而提升特征表达能力，降低训练复杂度，解决维度爆炸的问题，常用的如PCA主成分分析，LDA线性判别分析等，分别对应应用于无监督任务和监督任务，都是经典的线性方法，能有效解决大部分问题，但也存在一定的局限性，通过非线性的核映射等扩展方法能应用于复杂的非线性问题。

两者有相似的求解思路和过程，分别简单介绍一下

PCA

- PCA通过最大化投影方差，将数据投影到主轴上；
- 降维后方差尽可能大，保留的有效信息尽可能地多。
- 完全无监督学习，完全无参数限制，训练过程不需要任何人为参数设定或经验干预，结果只与数据有关，与用户是完全独立的。
- 变换后的少量维度具有不可解释性，无法具体说明该特征的含义
- 数据`x`的第k个主成分，即其协方差矩阵`Σ`的第k个特征值，将原数据按照第k个特征值对应的特征向量的单位向量进行投影即得降维后的结果。

LDA

- 类内方差小，类间方差大，可以保证降维后便于分类
- 同样是求解散度矩阵的前k个特征值特征向量即可；
- 最大化类间散度实际上优化的是每个类别的中心经过投影后离全局中心的投影足够远

> 本来看葫芦以为都看明白了，翻开蓝书瞅了两眼又迷糊了。

### 用过聚类吗？熟悉哪些聚类方法，各有什么优缺点？

聚类的本质还是要求达到类内高相似、类间高差异

- 最常用的k-means

  样本随机选k个点作为每一类的中心点，计算剩下各点到这些中心点的距离（当然这里的距离是广义距离，不一定是欧式的），将各点分配到距离最近的中心点，归属该类。再重新计算每一类新的中心点的位置，重复迭代，直到满足收敛条件；

  优点是直观简单，缺点是需要指定聚类的簇数，设置的不同的初始聚类中心会导致不稳定的结果。完全不适用于非凸数据和环形数据

- 层次聚类

  自下而上：每个样本点都作为一类，计算所有点两两之间的类间距离，将最近的两个合并醉成新的类，确定新的类中心。重复该步骤迭代直至满足条件。

  缺点：计算量巨大，迭代终止条件难以确定；

- 混合高斯模型

- 加上各类核方法





### 生成式模型和判别式模型有何区别？

假设可观测到的变量集合是`X`，需要预测的变量集合是`Y`，其他的变量集合是`Z`。

- 生成式模型：
  - 对==联合分布概率==`P(X,Y,Z)`进行建模，在给定观测集合`X`的条件下，通过计算边缘分布来得到对变量集合`Y`的推断
  - 关注数据如何生成，能够反映同类数据本身的相似度，不关心划分不同类的边界究竟在哪；
  - 常见：朴素贝叶斯、贝叶斯网络、混合高斯、KNN、隐马尔科夫HMM、马尔科夫随机场、LDA、深度信念网络；
- 判别式模型：
  - 直接对==条件概率==`P(Y,Z|X)`或决策函数`Y=f(X)`进行建模，然后消掉无关变量`Z`得到条件概率;
  - 关注类别间的差异，不能反映训练数据本身的特性，而是去寻找不同类别的最优的差异；
  - 常见：线性回归、逻辑回归、线性判别分析、支持向量机、CART、神经网络、高斯过程、条件随机场；
- 两种模型都是使后验概率最大化，判别式直接对后验概率建模，生成式通过贝叶斯定理将问题转化为求联合概率。
- 面试的时候用汉语、英语、法语、俄语的例子说明。

![preview](http://wy-typora-img.oss-cn-chengdu.aliyuncs.com/img/v2-c052779ddaa1b9d854658e161d9d2509_r.jpg)



## 过拟合

### 你是否遇到过模型过拟合的现象？你是如何解决的？

出现过拟合现象说明模型学习了太多训练样本的特征，导致泛化性能有限，在测试集上表现较差，我在之前参加阿里云的街景字符识别比赛中遇到过，可以采用的解决方法主要有以下几种：

- 做数据增强。从数据入手是解决过拟合问题最有力的方法之一，因为
- 集成学习

### 为什么设置正则项能减缓过拟合现象？



## 支持向量机

> 参考：
>
> https://zhuanlan.zhihu.com/p/93715996

### 简单讲一下SVM的原理？

SVM是一种二分类模型，在特征空间中寻找间隔最大化的分离超平面的线性分类器。

- 当训练样本线性可分时，通过硬间隔最大化，学习一个线性分类器，即线性可分支持向量机；
- 当训练数据近似线性可分时，引入松弛变量，通过软间隔最大化，学习一个线性分类器，即线性支持向量机；
- 当训练数据线性不可分时，通过使用核技巧及软间隔最大化，学习非线性支持向量机。

### 为什么要将求解SVM的原始问题转换为其对偶问题？

利用拉格朗日对偶性将求解线性可分支持向量机的原始最优化问题转换为求解对偶问题：

- 对偶问题往往更容易解决；
  - 为什么更好解决？因为降低了问题的复杂度，原来求特征向量，对偶只求alpha系数，该系数只有在支持向量处非零，其他都是零，所以很好求。
- 自然引入核函数，进而推广到更一般的非线性分类问题；

SVM原始问题时最大化，对偶问题时最小化

==拉格朗日对偶问题==

- 无论原问题是否凸优化，对偶问题都是凸优化问题；
- 满足一定条件时，原始问题核对偶问题的解完全等价。

### SVM的核函数有什么作用？

当样本在原始空间线性不可分时，可将样本从原始空间映射到一个更高维的特征空间，使样本在该特征空间内线性可分。

欧氏空间 → 希尔伯特空间

- 多项式核
- 线性核
- 高斯核
- 拉普拉斯核

详细说：

经过映射函数将原来的输入空间变换到一个新的特征空间，将输入空间中的内积 $x_i\cdot x_j$ 变换为特征空间中的内积$\phi(x_i) \cdot \phi(x_j)$，在新的特征空间中从训练样本学习支持向量机，核函数非线性的话学到的就是非线性支持向量机。

通过给定的核函数，隐式地在特征空间进行学习过程，利用求解线性分类问题的方法来求解非线性分类问题，此即为==核技巧==

### SVM对数据缺失敏感吗？

敏感，缺失了某些特征会导致向量数据不完整，SVM没有处理缺失值的策略，要在样本空间内线性可分，特征空间部分维度数据缺失会严重影响SVM性能。

### SVM如何防止过拟合？

引入松弛变量，目标函数里加入松弛变量的平方和限制一下。

### 加大训练数据量能提高SVM准确率吗？

不能

SVM本质是凸优化问题，如果增加的样本只是无效约束，并不会影响其最后的效果，因此一般来说SVM只适用于小样本数据量。

随样本量增大而改变模型特性的，是统计推断相关的东西，最大似然最大后验等相关的吧。